<html>
<head>
<title>CMU 15-418/618 (Spring 2013) Final Project</title>

<link rel="stylesheet" type="text/css" href="style.css">

</head>
<body>

<div class="constrainedWidth">
  
<div style="padding-bottom: 10px;">
<div class="title smallTitle">CMU 15-418/618 (Spring 2013) Final Project:</div>
<div class="title" style="width: 900px; padding-bottom: 6px; border-bottom: #000000 2px solid;">
    Interactive CPU-Based Ray Tracer
</div>
</div>

<div class="boldText">
<div>Nathan Slobody, Adam Wright</div>
</div>

<p><a href="proposal.html">Original Project Proposal</a></p>
<p><a href="checkpoint.html">Checkpoint Report</a></p>

<div class="section">Project Summary</div>

<p>
We have implemented a ray tracer utilizing bounding volume hierarchies (BVH) and packetized traversal on the CPU.  The BVH is built using the surface area heuristic (SAH) to produce BVHs that are inexpensive to traverse.  On Monday we plan to demonstrate our ray tracer rendering detailed scenes at interactive or near-interactive rates.
</p>

<div class="section">Background</div>

<p>
Ray tracing is a rendering technique that calculates the color displayed by an image at each pixel by "tracing" a ray through the scene starting at that pixel.  Since a ray may intersect with multiple objects in the scene, finding the point of closest intersection is a search problem which can be highly computation-intensive given the detail in typical images.
</p>
<p>
Naive algorithms for ray tracing can easily take many hours to traverse simple scenes, and even highly-efficient ray tracers can take long lengths of time given a high degree of desired realism.  Our goal was to implement a ray tracer that provides a reasonable level of realistic detail at an interactive frame rate.  
</p>
<p>
The ray tracing problem is embarassingly parallel in the sense that all rays are independent of one another, but the coherence of ray paths quickly breaks down within a typical scene and the resulting divergence can prove problematic for data parallel hardware such as GPUs.  In light of this, we chose to do our primary implementation on multi-core CPUs, where we can take advantage of separate cores that are able to gracefully handle branch instructions.
</p>

<div class="section">Approach</div>

<p>
There are two major axes of our implementation: a bounding volume hiearchy and packetization.
</p>

<p>
The creation of the BVH acceleration structure is done as a pre-processing step before any rays are traced through the scene.  The structure creates a bounding box around an entire model (containing arbitrary numbers of triangles) and recursively sub-partitions the interior triangles into smaller bounding boxes.  The actual triangles are referenced at the leaf nodes, with each leaf holding up to a pre-set number of triangles, which in our case is set to optimize for the SIMD width of our processors.
</p>

<img alt="Bounding Volume Hierarchy"src="bvh.png">

<p>
At each node of the tree, the choice of how to partition the interior triangles into two child nodes is done by evaluating the Surface Area Heuristic, which roughly tries to balance the surface area of the triangles in each child node of the parent BVH node.
</p>

<p>
Since we restricted ourselves to static scenes for the purposes of this project, we only have to build the BVH once.
</p>

<p>
Packetization involves evaluating multiple rays at once.  The normal ray tracing algorithm loops over all pixels on the screen, and for each pixel loops over all scene objects to find intersections.  By packetizing, we group a block of screen pixels together and trace a frustum through the scene rather than individual rays.  If the frustum does not intersect an object, then none of its interior rays will either, and the ray tracer can safely skip those rays in its computations. 
</p>

<p>
In addition, each packet can be easily mapped over a CPU core for high level parallelism by putting all packets into a shared work queue.  This seems to have the additional benefit of slightly reducing contention compared to individual pixels because of the larger compute time for each work item.
</p>

<p>
For packet intersection, we traverse the BVH and determine which rays can possibly intersect which objects. A frustum test is used to determine that the packet intersects the BVH; if it doesn't, all its rays can be disregarded for that object. Once the packet passes the frustum test for a node, the intersect function recurses on that node. As the packet descends into the BVH, rays that don't intersect are marked as inactive until there is a list of active rays and the triangles in the BVH they each active ray intersect. Our first packet based implementations just looped over each packet for intersection tests with bounding boxes and triangles. We then created an implementation that loops over all triangles at the leaf and intersects each ray in SIMD with that iteration's triangle. 
</p>

<p>
Once an intersection is found, the rays will reflect or refract, at which point the packet may no longer be coherent (the rays may not be tightly packed or going in similar directions).  From there the computation is done on a single lane of each core to minimized the effects of the resulting divergence.  
</p>

<p>
This approach should decrease the amount of time spent doing intersection tests, and push a little more work towards the part of the code that actually computes the value of each pixel.
</p>

<div class="section">Results</div>

<p>
The Happy Buddha image below contains over a million triangles and, with our current implementation, rendered in less than a second on our laptops (disregarding BVH build time, which only happens once).  We are continuing to iterate and hope to have this down considerably further by Monday as there are still a number of optimizations to make.  We anticipate a render rate of a few frames per second on scenes like this one.
</p>

<img alt="1 million triangle Buddha model"src="buddha.png">

<p>
Below is a table of our render times for both BVH building and traversal, for the different techniques we tried:
</p>

<center>
<table>
    <tr>
        <th rowspan="2">BVH Type</th>
        <th rowspan="2">Build</th>
        <th colspan="3">Traversal</th>
    </tr>
    <tr>
        <th>1 thread</th>
        <th>4 threads</th>
        <th>8 threads</th>
    </tr>
    <tr>
        <td style="text-align: left">Median Split</td>
        <td>1.04s</td>
        <td>7.92s</td>
        <td>2.21s</td>
        <td>1.75s</td>
    </tr>
    <tr>
        <td style="text-align: left">SAH</td>
        <td>8.77s</td>
        <td>3.95s</td>
        <td>1.09s</td>
        <td>0.87s</td>
    </tr>
</table>
</center>
<p>
By simply doing the traversal/pixel color computation across 8 threads on an Intel i7-2630QM CPU (4 physical cores + hyperthreading) we were able to obtain over 4x speedup. Hyperthreading accounts for the fact that we don't get a huge amount more speedup with greater than 4 cores. The near linear speedup is expected, since the splitting up the screen across multiple cores is embarrasingly parallel; each thread can write to its own part of the output image buffer, and threads only have to read from shared data structures, so there is no heavy contention.
</p>

<p>
Using ISPC for leaf intersection with a packet ended up slowing down execution by about 60%. Since our data structures are all Vector3 types, with x, y, and z floating point members and operator overloading, we had difficulties simply passing our data into ISPC. Converting from our data structures to an ISPC readable structure takes some time, and all of the gather/scatter operations required to service our array of structures (AOS) data will cause a big slow down.
</p>

Below is our profiling data. Intersecting primary rays takes a smaller percentage of the time than trace pixel, but reducing either would help significantly.

<center>
    <p>
    <table>
        <tr>
            <td><img src="sah_bvh_create_breakdown.png" /></td>
            <td><img src="trace_packet_breakdown.png" /></td>
        </tr>
        <tr>
            <td colspan="2">
                The left chart shows the breakdown for the creation of the Surface Area Heuristic BVH. Note that the time for "New Scratch" is so small it is diffcult to see. The creation time is dominated by choosing partition. The right chart shows the time breakdown for tracing a single packet. Both steps take significant time, but trace pixel is the bulk of the work.
            </td>
        </tr>
    </table>
    </p>
</center>

<p>
We got a speedup of about 2x from moving to SAH from BVH in terms of BVH traversal time, but build time increased drastically. This slow down is acceptable to us since we are focusing on getting an interactive static scene, so we only have to build the BVH one time. If there is time we may optimize this build process by not trying so many different splits, and also by reducing dynamic memory allocation.
</p>

<div class="section">Future Work</div>

There are several strategies that would be worth pursuing to improve performance for interactive ray tracing.

<div class="subsection">BVH Traversal</div>

BVH traversal is limited by intersection,
<ul>
    <li>SIMD: Convert data structures to be ISPC friendly and do packet intersection in SIMD</li>
    <li>Make tree 8-ary, traverse in parallel?</li>
    <li>Bring frustum test into BVH, more early exit</li>
</ul>

<div class="subsection">System Architecture</div>
<ul>
    <li>Do load balancing on the GPU and CPU: a piece of work is one call to trace pixel, if we can get large enough chunks of work (a large number of trace pixel requests), we can do chunks of them using SIMD (either GPU or ISPC). These SIMD operations could set some bit vectors (incident rays etc..)</li>
    <li>Shadow tests are more data parallel, since they don't recurse. This could potentially be done on the GPU, but still has some issues with SIMD since it involves BVH traversal</li>
</ul>

<div class="subsection">BVH Build</div>

<!-- Object load time also a bottleneck (though I feel like this won't be as big of a deal once the data's loaded into memory) -->

If we got to the point where we have gotten as much performance as possible out of interactive tracing, a good next step would be to support animation. The big barrier to doing this is the BVH build time. Since nodes access disjoint data, the build can be split without too much worry for contention. 

As shown in the breakdown for Trace Packet, the act of choosing the partition using SAH takes most of the time. This part of the algorithm requires doing partial sums of bounding boxes, and then computing the cost (as in equation SURFACEAREA_EQUATION). This could see some benefit from doing a prefix sum on the GPU, but good implementations top out at about 6x speedup [REFERENCE_TO_CUDA_SCAN].

The other option would be to do some kind of parallelization of building subtrees. For example, for a CPU with 8 cores, spawn off a new thread to continue the sub-tree traversal at depth 3, when there are 8 separate subtrees.

<div class="section">References</div>

<p>I. Wald, S. Boulos, and P. Shirley, <em>Ray Tracing Deformable Scenes Using Dynamic Bounding Volume Hierarchies</em>, 2007</p>

<p>I. Wald et al, <em>State of the Art in Ray Tracing Animated Scenes</em>, 2007</p>

<p>I. Wald, T. Ize, and S. Parker, <em>Fast, Parallel, and Asynchronous Construction of BVHs for Ray Tracing Animated Scenes</em>, 2007</p>

<p>Special thanks to Nico Feltman.</p>

<div class="section">List of Work By Each Student</div>

<p>We pair-programmed a good deal of the project and did roughly equal work.  Adam handled more of the BVH construction and Nathan more of the packetization.</p>

</div>

</body>
</html>
